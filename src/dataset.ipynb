{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07958483-1b50-4a56-94d6-e2ad18313bfa",
   "metadata": {},
   "source": [
    "# Get Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b7240245-3811-442f-8a1f-6f0b04b56314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e4c3e5e0-5cb9-4f12-a085-4a78f030a31d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 5000\n",
       "})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset, logging\n",
    "logging.set_verbosity_error()\n",
    "\n",
    "ds = load_dataset('bookcorpus', split='train[:5000]')\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33efd139-c5f9-47ff-822b-8ed45e484519",
   "metadata": {},
   "source": [
    "## Indexing the Model State Array with PyTorch\n",
    "\n",
    "hidden_states is a tuple of tensors/arrays. \n",
    "\n",
    "There is one tensor/array for each embedding in the network:\n",
    "hidden_states[i] == hidden states at i<sup>th</sup> layer of network.\n",
    "\n",
    "Each of these tensors/arrays has the following shape:\n",
    "hidden_states[i].shape == [num_examples, sequence_length, embedding_size]  \n",
    "\n",
    "To get the 13 different embeddings for a single token, we loop over the layers of hidden_states. We collect an example sentence isent, a token within that sentence itok, and all 768 scalar values in the embedding matrix using the colon indexer.\n",
    "\n",
    "For this example, we have:\n",
    " - 1 sentence\n",
    " - 7 is the sequence length\n",
    " - 13 layers, which is one input embedding *x*_i_ + 12 encoder blocks\n",
    " - 768 is the embedding size for BERT embeddings\n",
    " \n",
    "The result is a matrix of shpae [1 x 7 x 13 x 768]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fe5a321-726f-4150-88c1-62ac591ceaf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import logging, AutoModel, AutoTokenizer\n",
    "logging.set_verbosity_error()\n",
    "MODEL_NAME = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, use_fast=True)\n",
    "model = AutoModel.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f5e1fc3-4947-4ae3-aafe-3636caa5f432",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What is the max sequence length?\n",
    "max([len(tokenizer(s)['input_ids']) for s in ds['text']])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e42f567-1609-4c16-a276-554f00211f3a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## BERT lookup embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "ef374c6d-9b66-407e-8809-03794ff3535e",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_embeds = torch.Tensor(model.embeddings.word_embeddings.weight).detach()\n",
    "torch.save(bert_embeds, '../data/bert_lookup_embeddings.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df42f31a-9da1-4082-847e-cf06e938386e",
   "metadata": {},
   "source": [
    "## Process data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f4e94d31-082d-46a2-93f9-fede93d6fbe8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS] usually, he would be tearing around the living room, playing with his toys. [SEP]']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs = tokenizer(ds['text'][0], return_offsets_mapping=True, return_tensors='pt')\n",
    "[tokenizer.decode(x) for x in inputs.input_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76f4ca5d-a029-440c-a57b-86734baa737e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5000/5000 [01:22<00:00, 60.65it/s]\n"
     ]
    }
   ],
   "source": [
    "embeds = []\n",
    "\n",
    "for i, sample in enumerate(tqdm(ds['text'])):\n",
    "    batch_idx = 0 # one sample at a time, no batching.\n",
    "    \n",
    "    inputs = tokenizer(sample, return_offsets_mapping=True, return_tensors='pt')\n",
    "    \n",
    "    tok_char_start_inds = [st for st, _ in inputs.pop('offset_mapping')[batch_idx]]\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        hidden_states = model(**inputs,\n",
    "                              output_hidden_states=True)['hidden_states']\n",
    "        \n",
    "        \n",
    "    embeds.append(list(zip(\n",
    "        list(inputs.input_ids[batch_idx]),\n",
    "        tok_char_start_inds,\n",
    "        list(torch.stack(hidden_states, dim=2)[batch_idx]),\n",
    "    )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "38d76041-74d1-419b-95e0-6ff800b2541e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9344eba6-634e-42dc-b847-c86eb2e3e653",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(embeds, '../data/bookcorpus_embeddings_0_5000.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e440ba-62bc-4f02-b324-c73afd746c1b",
   "metadata": {},
   "source": [
    "## Linguistic Annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e056a22-049d-4b9a-8824-10d244cb73a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_trf')\n",
    "embeds = torch.load('../data/bookcorpus_embeddings_0_5000.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0e615e3-3a8b-46b5-a4f5-421c56fbb55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating new Docbin file\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3593bf01cc444c278e79078d84f58a2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/conda_envs/transformers/lib/python3.10/site-packages/torch/amp/autocast_mode.py:198: UserWarning: User provided device_type of 'cuda', but CUDA is not available. Disabling\n",
      "  warnings.warn('User provided device_type of \\'cuda\\', but CUDA is not available. Disabling')\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e762d201bc2d49f59eb4859dc5e9337b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5000 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from spacyfuncs import get_docs\n",
    "\n",
    "docs = get_docs(ds['text'],\n",
    "                '../data/bookcorpus_0_5000.spacy',\n",
    "                id_text_tuples=False,\n",
    "               )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:transformers]",
   "language": "python",
   "name": "conda-env-transformers-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
